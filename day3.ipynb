{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzuU9m-5XPRc"
      },
      "source": [
        "# Exploring Spark with Pandas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyzm8ivEXPRm"
      },
      "source": [
        "Using pandas examples, convert the analysis to pyspark. This is useful if you discover your data grows too large for your tooling.\n",
        "\n",
        "The purpose of this notebook is to familiarise yourself you the pyspark API. You are welcome to use the R version of this if you wish. As long as you are able to obtain the correct results. We will be using python in this notebook as it is quite widely used through data science and the community is very large.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOihFApaXPRn"
      },
      "source": [
        "#### Firstly, let's get our spark session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "imiSU7-bXPRp",
        "outputId": "29b5731d-2517-4c78-848a-fde36a7655fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No LSB modules are available.\n",
            "Distributor ID:\tUbuntu\n",
            "Description:\tUbuntu 22.04.2 LTS\n",
            "Release:\t22.04\n",
            "Codename:\tjammy\n"
          ]
        }
      ],
      "source": [
        "!lsb_release -a"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update"
      ],
      "metadata": {
        "id": "HFcOLnho7YFo",
        "outputId": "9559a839-2195-4d6d-e283-2775d4099786",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [1 InRelease 14.2 kB/110\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [498 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:8 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,014 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [998 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,260 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,283 kB]\n",
            "Hit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 5,396 kB in 2s (3,155 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install java\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "metadata": {
        "id": "sw5L1WpS7aPN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get spark\n",
        "VERSION='3.5.0'\n",
        "!wget https://dlcdn.apache.org/spark/spark-$VERSION/spark-$VERSION-bin-hadoop3.tgz"
      ],
      "metadata": {
        "id": "NfOSg-xD7dAk",
        "outputId": "a130bbea-e063-4cd3-cb73-008e55685056",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-09-21 18:14:01--  https://dlcdn.apache.org/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz\n",
            "Resolving dlcdn.apache.org (dlcdn.apache.org)... 151.101.2.132, 2a04:4e42::644\n",
            "Connecting to dlcdn.apache.org (dlcdn.apache.org)|151.101.2.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 400395283 (382M) [application/x-gzip]\n",
            "Saving to: ‘spark-3.5.0-bin-hadoop3.tgz’\n",
            "\n",
            "spark-3.5.0-bin-had 100%[===================>] 381.85M  46.3MB/s    in 5.6s    \n",
            "\n",
            "2023-09-21 18:14:07 (68.0 MB/s) - ‘spark-3.5.0-bin-hadoop3.tgz’ saved [400395283/400395283]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# decompress spark\n",
        "!tar xf spark-$VERSION-bin-hadoop3.tgz\n",
        "\n",
        "# install python package to help with system paths\n",
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "emDGvNp87gDX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let Colab know where the java and spark folders are\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/spark-{VERSION}-bin-hadoop3\""
      ],
      "metadata": {
        "id": "ZyUuPFOW7i0L"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "import pandas as pd\n",
        "spark = SparkSession.builder.appName(\"local[*]\").getOrCreate()"
      ],
      "metadata": {
        "id": "AyxL2hvQ7TJA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_QuXHX5XPRt"
      },
      "source": [
        "### Overview\n",
        "\n",
        "\n",
        "* Joining two dataframes/data sets\n",
        "* Simple aggregations\n",
        "* Persisting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "907SSmKtXPRu"
      },
      "source": [
        "#### JOIN: Pandas\n",
        "\n",
        "We won't use this more in this notebook, but observe how the joins work.\n",
        "\n",
        "We what happens if you change from the default inner join to outer joins."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhfTHJLuXPRu"
      },
      "outputs": [],
      "source": [
        "customer_raw = [(1, 'bob', 3462543658686),\n",
        "           (2, 'rob', 9087567565439),\n",
        "           (3, 'tim', 5436586999467),\n",
        "           (4, 'tom', 8349756853250)]\n",
        "\n",
        "customer_cols = ['id', 'name', 'credit_card_number']\n",
        "\n",
        "\n",
        "\n",
        "orders_raw = [(1, 'ketchup', 'bob', 1.20),\n",
        "           (2, 'rutabaga', 'bob', 3.35),\n",
        "           (3, 'fake vegan meat', 'rob', 13.99),\n",
        "           (4, 'cheesey poofs', 'tim', 3.99),\n",
        "           (5, 'ice cream', 'tim', 4.95),\n",
        "           (6, 'protein powder', 'tom', 49.95)]\n",
        "\n",
        "orders_cols = ['id', 'product_name', 'customer', 'price']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yp4UJ8vjXPRv"
      },
      "outputs": [],
      "source": [
        "customer_df = pd.DataFrame(customer_raw, columns=customer_cols)\n",
        "orders_df = pd.DataFrame(orders_raw, columns=orders_cols)\n",
        "\n",
        "customer_df\n",
        "\n",
        "joined_df = pd.merge(customer_df, orders_df, how='inner', left_on='name', right_on='customer')\n",
        "joined_df\n",
        "\n",
        "## For self study. What happens if (4, 'tom', 8349756853250) in valuesA becomes (4, 'tod', 8349756853250)\n",
        "## How do the results change?\n",
        "## More sensibly; what if customers have not made any orders but we still require them in the result set?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aE93AHODXPRw"
      },
      "source": [
        "#### JOIN: Spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfZ3y2OGXPRx"
      },
      "outputs": [],
      "source": [
        "customersDF = spark.createDataFrame(customer_raw, customer_cols)\n",
        "\n",
        "ordersDF = spark.createDataFrame(orders_raw, orders_cols)\n",
        "\n",
        "# Show tables\n",
        "customersDF.show()\n",
        "ordersDF.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGUJZ23LXPRx"
      },
      "outputs": [],
      "source": [
        "joinedDF = customersDF.join(ordersDF, customersDF.name == ordersDF.customer)\n",
        "joinedDF.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGVpzIwQXPRy"
      },
      "source": [
        "## Simple Aggregations\n",
        "\n",
        "Now let's explore simple aggregations. You will be using these often when doing exploratory work in big data. Remember, the intention here is that you grow familiar with the way the API works, and how to translate inquiries into that API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IiGgWJNXPRz"
      },
      "source": [
        "> _How much did each person spend?_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUaed3CgXPR0"
      },
      "outputs": [],
      "source": [
        "joined_df.groupby('name').agg({\"price\": [\"sum\"]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CRoO4QYXPR1"
      },
      "outputs": [],
      "source": [
        "import pyspark.sql.functions as f\n",
        "\n",
        "joinedDF.groupby('name').agg(f.sum('price').alias('total')).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzveYzzQXPR1"
      },
      "source": [
        "Let's use bigger data\n",
        "  * NYC crash data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "B0R_U_13XPR2",
        "outputId": "840bd694-ffad-44d0-fe11-811178d22b2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  411M    0  411M    0     0  3136k      0 --:--:--  0:02:14 --:--:-- 2563k\n"
          ]
        }
      ],
      "source": [
        "# save to the filesystem to prevent another load\n",
        "! curl -o rows.csv https://data.cityofnewyork.us/api/views/h9gi-nx95/rows.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "N8yB9gVcXPR3",
        "outputId": "4a3ab35d-11cb-4215-9795-76c25bbe0c30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-a70f860f02a9>:2: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  nyc_df = pd.read_csv('rows.csv')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "nyc_df = pd.read_csv('rows.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OwQJ-vvJXPR4",
        "outputId": "4e4d456a-ffbb-46ee-e3ba-d07a29782f26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026884\n"
          ]
        }
      ],
      "source": [
        "# number or rows\n",
        "\n",
        "print(len(nyc_df))\n",
        "\n",
        "# this is quite large so we will work with a sample while we experiment in pandas as least."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6mwKfURXPR4"
      },
      "source": [
        "We'll take a random sample at 20% of the original data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "96qLX4b5XPR5"
      },
      "outputs": [],
      "source": [
        "nyc_small = nyc_df.sample(frac=0.2, replace=False, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WnQ14hc2XPR6"
      },
      "outputs": [],
      "source": [
        "# we are also going to limit the columns to those we are going to work with\n",
        "\n",
        "nyc_small = nyc_small[['CRASH DATE', 'CONTRIBUTING FACTOR VEHICLE 1',\n",
        "                       'BOROUGH', 'VEHICLE TYPE CODE 1',\n",
        "                       'NUMBER OF PERSONS INJURED']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "yWuPN42QXPR7",
        "outputId": "38a47fe9-063e-4ca7-8cfe-442f50c7b441",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         CRASH DATE   CONTRIBUTING FACTOR VEHICLE 1   BOROUGH  \\\n",
              "1424989  11/28/2014              Turning Improperly  BROOKLYN   \n",
              "1422316  12/19/2014  Driver Inattention/Distraction  BROOKLYN   \n",
              "\n",
              "                    VEHICLE TYPE CODE 1  NUMBER OF PERSONS INJURED  \n",
              "1424989               PASSENGER VEHICLE                        0.0  \n",
              "1422316  LARGE COM VEH(6 OR MORE TIRES)                        0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-12272e58-7573-4260-b69f-84966580aabf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRASH DATE</th>\n",
              "      <th>CONTRIBUTING FACTOR VEHICLE 1</th>\n",
              "      <th>BOROUGH</th>\n",
              "      <th>VEHICLE TYPE CODE 1</th>\n",
              "      <th>NUMBER OF PERSONS INJURED</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1424989</th>\n",
              "      <td>11/28/2014</td>\n",
              "      <td>Turning Improperly</td>\n",
              "      <td>BROOKLYN</td>\n",
              "      <td>PASSENGER VEHICLE</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1422316</th>\n",
              "      <td>12/19/2014</td>\n",
              "      <td>Driver Inattention/Distraction</td>\n",
              "      <td>BROOKLYN</td>\n",
              "      <td>LARGE COM VEH(6 OR MORE TIRES)</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-12272e58-7573-4260-b69f-84966580aabf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-12272e58-7573-4260-b69f-84966580aabf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-12272e58-7573-4260-b69f-84966580aabf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8c0ec310-8d14-4872-ad31-a5fb58042980\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8c0ec310-8d14-4872-ad31-a5fb58042980')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8c0ec310-8d14-4872-ad31-a5fb58042980 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "nyc_small.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQcJobyIXPR8"
      },
      "source": [
        "Now, let's create the pyspark dataframe. Now we two frames with the same content\n",
        "  * nyc_small: pandas\n",
        "  * sdf_small: pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "hee_eOQhXPR9",
        "outputId": "c3c0d0fb-c201-457c-b443-f6a6c69f8548",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/spark-3.5.0-bin-hadoop3/python/pyspark/sql/context.py:113: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "StructType([StructField('CRASH DATE', StringType(), True), StructField('CONTRIBUTING FACTOR VEHICLE 1', StringType(), True), StructField('BOROUGH', StringType(), True), StructField('VEHICLE TYPE CODE 1', StringType(), True), StructField('NUMBER OF PERSONS INJURED', StringType(), True)])\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SQLContext\n",
        "\n",
        "\n",
        "# there are nan's in the frame with strings, and spark can't 'infer the schema', so we have to help it out\n",
        "# by replacing them with empty strings and forcing the column to be a string\n",
        "\n",
        "sdf_small = SQLContext(spark).createDataFrame(nyc_small.fillna('').astype('str'))\n",
        "\n",
        "\n",
        "# Lets check the schema quickly\n",
        "\n",
        "print(sdf_small.schema)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fb2AqiRtXPR-"
      },
      "source": [
        "# Questions\n",
        "\n",
        "Answer the following questions by porting the pandas code to the Spark API\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lasJs_j9XPR_"
      },
      "source": [
        "\n",
        "# Question 1\n",
        "\n",
        "\n",
        "> On what day do most crashes occcur?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvUHxwKyXPR_"
      },
      "outputs": [],
      "source": [
        "# Pandas\n",
        "nyc_small.groupby('CRASH DATE')['CRASH DATE'].count().sort_values(ascending=False).head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Eio1I_VrXPSA",
        "outputId": "6a7472ac-decd-40a8-dd7b-c5fc899d9b5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------------+\n",
            "|CRASH DATE|count(CRASH DATE)|\n",
            "+----------+-----------------+\n",
            "|11/15/2018|              228|\n",
            "|01/21/2014|              219|\n",
            "|05/19/2017|              205|\n",
            "|06/21/2018|              196|\n",
            "|12/15/2017|              194|\n",
            "+----------+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "### Spark?\n",
        "\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Group by 'CRASH DATE', count, and order by count in descending order\n",
        "result = sdf_small.groupBy(['CRASH DATE']).agg({'CRASH DATE': 'count'})\\\n",
        "                  .orderBy(col('count(CRASH DATE)').desc()) \\\n",
        "                  .limit(5)\n",
        "\n",
        "# Show the result\n",
        "result.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtcFGV-yXPSB"
      },
      "source": [
        "# Question 2\n",
        "\n",
        "> _Where do most crashes occur?_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3p-cPu4jXPSC"
      },
      "outputs": [],
      "source": [
        "nyc_small.groupby('BOROUGH')['BOROUGH'].count().sort_values(ascending=False).head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "8Ncy9bcvXPSD",
        "outputId": "b7f1d9cc-d8c3-4d61-9df5-8447e9a9b1c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------------+\n",
            "|  BOROUGH|count(BOROUGH)|\n",
            "+---------+--------------+\n",
            "|         |        126088|\n",
            "| BROOKLYN|         88569|\n",
            "|   QUEENS|         74822|\n",
            "|MANHATTAN|         62911|\n",
            "|    BRONX|         41229|\n",
            "+---------+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## Spark?\n",
        "\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "result = sdf_small.groupBy('BOROUGH').agg({'BOROUGH': 'count'}) \\\n",
        "                  .orderBy(col('count(BOROUGH)').desc()) \\\n",
        "                  .limit(5)\n",
        "\n",
        "result.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWjn6DeaXPSE"
      },
      "source": [
        " # Question 3\n",
        "\n",
        " > What is the most common cause of accident in 'QUEENS'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkvcFNKiXPSK"
      },
      "outputs": [],
      "source": [
        "nyc_small[(nyc_small.BOROUGH == 'QUEENS')]['CONTRIBUTING FACTOR VEHICLE 1'].value_counts()\n",
        "\n",
        "# you can also use a group by (to avoid the pandas value_counts function)\n",
        "\n",
        "nyc_small[(nyc_small.BOROUGH == 'QUEENS')].groupby(\n",
        "    'CONTRIBUTING FACTOR VEHICLE 1'\n",
        ")['CONTRIBUTING FACTOR VEHICLE 1'].count().sort_values(ascending=False).head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "w3piHywcXPSM",
        "outputId": "0641f9ea-3f11-4a9a-b8df-f415e5b349ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------+-----+\n",
            "|CONTRIBUTING FACTOR VEHICLE 1|count|\n",
            "+-----------------------------+-----+\n",
            "|                  Unspecified|26554|\n",
            "|         Driver Inattentio...|15937|\n",
            "|         Failure to Yield ...| 6322|\n",
            "|             Backing Unsafely| 3673|\n",
            "|         Following Too Clo...| 2708|\n",
            "|         Passing or Lane U...| 1954|\n",
            "|          Passing Too Closely| 1758|\n",
            "|         Traffic Control D...| 1590|\n",
            "|           Turning Improperly| 1544|\n",
            "|              Fatigued/Drowsy| 1275|\n",
            "|              Other Vehicular| 1199|\n",
            "|          Driver Inexperience| 1068|\n",
            "|          Alcohol Involvement|  975|\n",
            "|                 Unsafe Speed|  954|\n",
            "|         Unsafe Lane Changing|  678|\n",
            "|            Pavement Slippery|  668|\n",
            "|         Prescription Medi...|  582|\n",
            "|           Lost Consciousness|  577|\n",
            "|         View Obstructed/L...|  569|\n",
            "|          Physical Disability|  551|\n",
            "+-----------------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## Spark?\n",
        "\n",
        "from pyspark.sql.functions import col, count\n",
        "\n",
        "result = sdf_small.filter(col('BOROUGH') == 'QUEENS') \\\n",
        "                  .groupBy('CONTRIBUTING FACTOR VEHICLE 1') \\\n",
        "                  .agg(count('*').alias('count')) \\\n",
        "                  .orderBy(col('count').desc())\n",
        "\n",
        "result.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zykJIVXXPSO"
      },
      "source": [
        "# Question 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8XENdS2XPSP"
      },
      "source": [
        "> _What is the average number or injuries for specific cars driving in specific suburbs_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XcQBW4-XPSQ"
      },
      "outputs": [],
      "source": [
        "nyc_small.groupby(['VEHICLE TYPE CODE 1', 'BOROUGH'])['NUMBER OF PERSONS INJURED'].mean().sort_values(ascending=False).head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "FCkWKOPNXPSQ",
        "outputId": "b101fccc-659f-4414-aa9d-b60a63d41ce8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------+------------+\n",
            "|VEHICLE TYPE CODE 1| BOROUGH|avg_injuries|\n",
            "+-------------------+--------+------------+\n",
            "|                rmb|  QUEENS|        11.0|\n",
            "|                 PC|BROOKLYN|         5.0|\n",
            "|          AMBULANVE|   BRONX|         4.0|\n",
            "+-------------------+--------+------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## Spark?\n",
        "\n",
        "from pyspark.sql.functions import col, mean\n",
        "\n",
        "result = sdf_small.groupBy('VEHICLE TYPE CODE 1', 'BOROUGH') \\\n",
        "                  .agg(mean('NUMBER OF PERSONS INJURED').alias('avg_injuries')) \\\n",
        "                  .orderBy(col('avg_injuries').desc()) \\\n",
        "                  .limit(3)\n",
        "\n",
        "result.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}